{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1215351f-10dc-4af6-9045-33187120207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.7/site-packages (1.8.9)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.0.3)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.2)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.42.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.19.1)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.0.0)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.13 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.13)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.7.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.12.8)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: absl-py<=0.11,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.11.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.13)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<=0.11,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.13.3)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.2)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (1.31.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.7.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (58.5.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.1.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.25.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2021.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.53.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (2.20)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install kfp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f0bcff2-3ffb-4e51-b852-511cb10ad0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp\n",
    "from kfp.components import OutputPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afffb0-449b-4669-807a-793f526277fe",
   "metadata": {},
   "source": [
    "#### Pipeline Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "abf6aad4-f675-47aa-820b-14daa796d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Google Cloud project that this pipeline runs in.\n",
    "project_id = \"de2021-324520\"\n",
    "# The region that this pipeline runs in\n",
    "region = \"us-west1\"\n",
    "# Specify a Cloud Storage URI that your pipelines service account can access. The artifacts of your pipeline runs are stored within the pipeline root.\n",
    "pipeline_root_path = \"gs://dejads_temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bace39-57ba-49ee-bd74-9eaf4093f471",
   "metadata": {},
   "source": [
    "#### Create Pipeline Components\n",
    "\n",
    "We can create a component from Python functions (inline) and from a container. We will first try inline python functions. \n",
    "\n",
    "Step 1: Define the python function\n",
    "\n",
    "Step 2:  Use **kfp.components.create_component_from_func** build the component. This function takes four parameters.\n",
    "\n",
    "**1.func**: The Python function to convert.\n",
    "\n",
    "**2.base_image**: (Optional.) Specify the Docker container image to run this function in. \n",
    "\n",
    "**3.output_component_file**: (Optional.) Writes your component definition to a file. \n",
    "\n",
    "**4.packages_to_install**: (Optional.) A list of versioned Python packages to install before running your function.\n",
    "\n",
    "Another thing we need to consider is passing parameters between components. We can pass simple parameters such as integer, string, tuple, dict, and list by values. To pass the large datasets or complex configurations, we can use files. We can annotate the Python functionâ€™s parameters to indicate input or output files for the component. \n",
    "\n",
    "Refer to  https://www.kubeflow.org/docs/components/pipelines/sdk/python-function-components/ for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457ef88-cd95-4304-b6e0-143b718c44aa",
   "metadata": {},
   "source": [
    "#### Pipeline Component : Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83bc305f-2456-4c07-b89f-427b0f24eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def download_data(project_id: str, bucket: str, file_name: str) -> Dict:\n",
    "    '''download data'''\n",
    "    from google.cloud import storage\n",
    "    import pandas as pd\n",
    "    import logging \n",
    "    import sys\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.get_bucket(bucket)\n",
    "    blob = bucket.blob(file_name)\n",
    "    local_path = '/tmp/'+ file_name\n",
    "    blob.download_to_filename(local_path)\n",
    "    logging.info('Downloaded Data!')\n",
    "    dict_from_csv = pd.read_csv(local_path, index_col=None, squeeze=True).to_dict()\n",
    "    logging.info('Returning Data as Dictionary Object!')\n",
    "    return dict_from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e32942c5-9171-4724-b8f7-e5fb7ab6a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KFP component for data ingestion\n",
    "data_ingestion_comp = comp.create_component_from_func(\n",
    "    download_data, output_component_file='data_ingestion.yaml', packages_to_install=['google-cloud-storage', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3494d2-bea7-415f-9832-fcf1f2c9fe4a",
   "metadata": {},
   "source": [
    "#### Pipeline Component : Training-MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e194fc48-1343-4bd5-9c69-f3d1ce826321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Dict\n",
    "def train_mlp (features: Dict, project_id: str, model_repo: str) -> Dict:\n",
    "    '''train a MLP with default parameters'''\n",
    "    import pandas as pd\n",
    "    from google.cloud import storage\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    import json\n",
    "    import logging \n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(features)  \n",
    "    \n",
    "    logging.info(df.columns)\n",
    "        \n",
    "    # split into input (X) and output (Y) variables\n",
    "    X = df.loc[:, ['ntp','age', 'bmi', 'dbp', 'dpf', 'pgc', 'si', 'tsft']].values\n",
    "    Y = df.loc[:, ['class']].values\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X, Y, verbose=0)\n",
    "    logging.info(model.metrics_names)\n",
    "    metrics = {\n",
    "        \"accuracy\": scores[1],\n",
    "        \"loss\": scores[0],\n",
    "    }\n",
    "   \n",
    "    # Save the model localy\n",
    "    local_file = '/tmp/local_model.h5'\n",
    "    model.save(local_file)\n",
    "     # write out output\n",
    "  \n",
    "    # Save to GCS as model.h5\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.get_bucket(model_repo)\n",
    "    blob = bucket.blob('model.h5')\n",
    "        # Upload the locally saved model\n",
    "    blob.upload_from_filename(local_file)\n",
    "        # Clean up\n",
    "    # os.remove(local_file)\n",
    "    print(\"Saved the model to GCP bucket : \" + model_repo)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f670759-2b2b-4636-a941-44b741e1a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KFP component for training \n",
    "train_mlp_com = comp.create_component_from_func(\n",
    "    train_mlp, output_component_file='training_mlp.yaml', packages_to_install=['google-cloud-storage', 'pandas', 'keras', 'tensorflow', 'h5py', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911d312-549c-4be7-bef0-e02c9d8cf80f",
   "metadata": {},
   "source": [
    "#### Pipeline Component : Training LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "acee72f0-007a-4e9c-853a-e6cf66f2a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Dict\n",
    "def train_lr (features: Dict, project_id: str, model_repo: str) -> Dict:\n",
    "    '''train a LogisticRegression with default parameters'''\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from google.cloud import storage\n",
    "    import json\n",
    "    import logging \n",
    "    import sys\n",
    "    import os\n",
    "    import joblib\n",
    "        \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(features)  \n",
    "    \n",
    "    logging.info(df.columns)        \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.drop('class',axis=1), \n",
    "                                                    df['class'], test_size=0.30, \n",
    "                                                    random_state=101)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": model.score(x_test, y_test)\n",
    "    }\n",
    "    logging.info(metrics)\n",
    "   \n",
    "    # Save the model localy\n",
    "    local_file = '/tmp/local_model.pkl'\n",
    "    joblib.dump(model, local_file)\n",
    "     # write out output\n",
    "  \n",
    "    # Save to GCS as model.h5\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.get_bucket(model_repo)\n",
    "    blob = bucket.blob('lrmodel.pkl')\n",
    "        # Upload the locally saved model\n",
    "    blob.upload_from_filename(local_file)\n",
    "        # Clean up\n",
    "    # os.remove(local_file)\n",
    "    print(\"Saved the model to GCP bucket : \" + model_repo)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1cf96ee3-a573-4c26-bb23-0c291786e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KFP component for training lr model\n",
    "trail_lr_com = comp.create_component_from_func(\n",
    "    train_lr, output_component_file='train_lr_model.yaml', packages_to_install=['google-cloud-storage', 'pandas', 'joblib', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b9f62-14d3-4b97-bd9a-f15b3d47758a",
   "metadata": {},
   "source": [
    "#### Pipeline Component : Prediction-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa57d2d1-2a2b-4c43-8a3b-1399471e782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(project_id: str, model_repo: str, features: Dict) -> Dict:\n",
    "    import pandas as pd\n",
    "    from keras.models import load_model\n",
    "    from google.cloud import storage\n",
    "    import json\n",
    "    import logging\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(features)\n",
    "    \n",
    "    xNew = df.loc[:, ['ntp', 'age', 'bmi', 'dbp', 'dpf', 'pgc', 'si', 'tsft']].values\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.get_bucket(model_repo)\n",
    "    blob = bucket.blob('model.h5')\n",
    "    blob.download_to_filename('/tmp/local_model.h5')\n",
    "    model = load_model('/tmp/local_model.h5')\n",
    "    dfcp = df.copy()\n",
    "    result = model.predict(xNew)   \n",
    "    y_classes = result.argmax(axis=-1)\n",
    "    logging.info(y_classes)\n",
    "    dfcp['pclass'] = y_classes.tolist()\n",
    "    dic = dfcp.to_dict(orient='records')   \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a9af09f-9cbc-4639-aba8-7ec50070f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KFP component for prediction \n",
    "prediction_mpl_com = comp.create_component_from_func(\n",
    "    predict, output_component_file='prediction_mlp_com.yaml', packages_to_install=['google-cloud-storage', 'pandas', 'keras', 'tensorflow', 'h5py', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4e9c1-a1d4-412f-8533-8e741fd3f79c",
   "metadata": {},
   "source": [
    "#### Pipeline Component : Prediction-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e70377d6-f3f8-4320-9689-9e17a695674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lr(project_id: str, model_repo: str, features: Dict) -> Dict:\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    from google.cloud import storage\n",
    "    import json\n",
    "    import logging\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(features)    \n",
    "    \n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.get_bucket(model_repo)\n",
    "    blob = bucket.blob('lrmodel.pkl')\n",
    "    filename = '/tmp/local_model.pkl'\n",
    "    blob.download_to_filename(filename)\n",
    "        \n",
    "    #Loading the saved model with joblib\n",
    "    model = joblib.load(filename)\n",
    "\n",
    "    xNew = df[['ntp', 'age', 'bmi', 'dbp', 'dpf', 'pgc', 'si', 'tsft']]\n",
    "\n",
    "    dfcp = df.copy()   \n",
    "    y_classes = model.predict(xNew)\n",
    "    logging.info(y_classes)\n",
    "    dfcp['pclass'] = y_classes.tolist()\n",
    "    dic = dfcp.to_dict(orient='records') \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8f0dbde-9fee-4d37-b81e-6ea4abdbceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KFP component for prediction LR \n",
    "prediction_lr_com = comp.create_component_from_func(\n",
    "    predict_lr, output_component_file='prediction_lr_com.yaml', packages_to_install=['google-cloud-storage', 'pandas', 'joblib', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c183e7-f9dd-48d7-b37e-69646bb08203",
   "metadata": {},
   "source": [
    "#### Pipeline Component : Algorithm Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "752057b5-8389-4370-97d5-19e30ebb8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Dict\n",
    "\n",
    "def compare_model(mlp_metrics: Dict, lr_metrics: Dict) -> str:\n",
    "    import logging\n",
    "    import json\n",
    "    import sys\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    logging.info(mlp_metrics)\n",
    "    logging.info(lr_metrics)\n",
    "    if mlp_metrics.get(\"accuracy\") > lr_metrics.get(\"accuracy\"):\n",
    "        return \"MLP\"\n",
    "    else :\n",
    "        return \"LR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7afc0675-1e45-4f52-8f1d-986d8f6f7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KFP component for selecting between MLP and LR\n",
    "compare_model_com = comp.create_component_from_func(\n",
    "    compare_model, output_component_file='alogo_selecion_com.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166590b3-f788-4e4c-8e31-fb981da56966",
   "metadata": {},
   "source": [
    "#### Define the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a96b6ae0-234b-4883-ae95-8599689a5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow of the pipeline.\n",
    "@kfp.dsl.pipeline(\n",
    "    name=\"lab10-v1\",\n",
    "    pipeline_root=pipeline_root_path)\n",
    "def pipeline(project_id: str, data_bucket: str, trainset_filename: str, model_repo: str, testset_filename: str, ):\n",
    "    \n",
    "    \n",
    "    di_op = data_ingestion_comp(\n",
    "        project_id=project_id,\n",
    "        bucket=data_bucket,\n",
    "        file_name=trainset_filename\n",
    "    )\n",
    "\n",
    " \n",
    "    training_mlp_job_run_op = train_mlp_com(\n",
    "        project_id=project_id,\n",
    "        model_repo=model_repo,       \n",
    "        features=di_op.output\n",
    "    )\n",
    "    \n",
    "     \n",
    "    training_lr_job_run_op = trail_lr_com(\n",
    "        project_id=project_id,\n",
    "        model_repo=model_repo,       \n",
    "        features=di_op.output\n",
    "    )\n",
    "    \n",
    "    pre_di_op = data_ingestion_comp(\n",
    "        project_id=project_id,\n",
    "        bucket=data_bucket,\n",
    "        file_name=testset_filename\n",
    "    ).after(training_mlp_job_run_op, training_lr_job_run_op)\n",
    "        \n",
    "        \n",
    "    comp_model__op = compare_model_com(training_mlp_job_run_op.output,\n",
    "                                       training_lr_job_run_op.output).after(training_mlp_job_run_op, training_lr_job_run_op)  \n",
    "    \n",
    "    # defining the branching condition\n",
    "    with dsl.Condition(comp_model__op.output==\"MLP\"):\n",
    "        predict_mlp_job_run_op = prediction_mpl_com(\n",
    "        project_id=project_id,\n",
    "        model_repo=model_repo,       \n",
    "        features=pre_di_op.output\n",
    "        )\n",
    "    with dsl.Condition(comp_model__op.output==\"LR\"):\n",
    "        predict_lr_job_run_op = prediction_lr_com(\n",
    "        project_id=project_id,\n",
    "        model_repo=model_repo,       \n",
    "        features=pre_di_op.output\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac278200-c580-4f40-bc8b-1817d3b13c13",
   "metadata": {},
   "source": [
    "#### Compile the pipeline into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f8ee4b21-89e6-4f63-845c-b249556ea919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='diabetes_predictor_pipeline3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "344f4f38-2a72-4264-8711-c88187c72089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.19.7)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.42.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.30.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.31.4)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (21.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (3.19.1)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.35.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (58.5.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2.25.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2021.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.53.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.41.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.1.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (4.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.26.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (4.0.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87025e-08d7-4608-b37d-c929b6eb5a3c",
   "metadata": {},
   "source": [
    "#### Submit the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b88e89-42cd-4e64-bc4e-8e3eddebccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/411957191814/locations/us-central1/pipelineJobs/lab9-v1-20211122162553\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/411957191814/locations/us-central1/pipelineJobs/lab9-v1-20211122162553')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/lab9-v1-20211122162553?project=411957191814\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/411957191814/locations/us-central1/pipelineJobs/lab9-v1-20211122162553\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=\"lab10-v1-diabetes-predictor\",\n",
    "    template_path=\"diabetes_predictor_pipeline3.json\",\n",
    "    pipeline_root=pipeline_root_path,\n",
    "    parameter_values={\n",
    "        'project_id': project_id,\n",
    "        'data_bucket': 'dejads_input',\n",
    "        'trainset_filename': 'training_set.csv',\n",
    "        'testset_filename': 'prediction_set.csv',\n",
    "        'model_repo':'model_repo_de2021'\n",
    "    }\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
